{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create empty list to store reviews\n",
    "reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 3821 total reviews\n",
      "Scraping page 2\n",
      "   ---> 3921 total reviews\n",
      "Scraping page 3\n",
      "   ---> 4021 total reviews\n",
      "Scraping page 4\n",
      "   ---> 4121 total reviews\n",
      "Scraping page 5\n",
      "   ---> 4221 total reviews\n",
      "Scraping page 6\n",
      "   ---> 4321 total reviews\n",
      "Scraping page 7\n",
      "   ---> 4421 total reviews\n",
      "Scraping page 8\n",
      "   ---> 4521 total reviews\n",
      "Scraping page 9\n",
      "   ---> 4621 total reviews\n",
      "Scraping page 10\n",
      "   ---> 4721 total reviews\n",
      "Scraping page 11\n",
      "   ---> 4821 total reviews\n",
      "Scraping page 12\n",
      "   ---> 4921 total reviews\n",
      "Scraping page 13\n",
      "   ---> 5021 total reviews\n",
      "Scraping page 14\n",
      "   ---> 5121 total reviews\n",
      "Scraping page 15\n",
      "   ---> 5221 total reviews\n",
      "Scraping page 16\n",
      "   ---> 5321 total reviews\n",
      "Scraping page 17\n",
      "   ---> 5421 total reviews\n",
      "Scraping page 18\n",
      "   ---> 5521 total reviews\n",
      "Scraping page 19\n",
      "   ---> 5621 total reviews\n",
      "Scraping page 20\n",
      "   ---> 5721 total reviews\n",
      "Scraping page 21\n",
      "   ---> 5821 total reviews\n",
      "Scraping page 22\n",
      "   ---> 5921 total reviews\n",
      "Scraping page 23\n",
      "   ---> 6021 total reviews\n",
      "Scraping page 24\n",
      "   ---> 6121 total reviews\n",
      "Scraping page 25\n",
      "   ---> 6221 total reviews\n",
      "Scraping page 26\n",
      "   ---> 6321 total reviews\n",
      "Scraping page 27\n",
      "   ---> 6421 total reviews\n",
      "Scraping page 28\n",
      "   ---> 6521 total reviews\n",
      "Scraping page 29\n",
      "   ---> 6621 total reviews\n",
      "Scraping page 30\n",
      "   ---> 6721 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 30\n",
    "page_size = 100\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | This was our first flight wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified | I recently encountered a hig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Beware! BA don't provide any r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |  Check in was chaotic and ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified | All 4 of our flights were fine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  ✅ Trip Verified | This was our first flight wi...\n",
       "1  ✅ Trip Verified | I recently encountered a hig...\n",
       "2  Not Verified |  Beware! BA don't provide any r...\n",
       "3  ✅ Trip Verified |  Check in was chaotic and ba...\n",
       "4  Not Verified | All 4 of our flights were fine ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
